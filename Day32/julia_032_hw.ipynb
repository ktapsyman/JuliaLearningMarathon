{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 深度學習：類神經網路模型簡介\n",
    "\n",
    "## 作業 032：訓練 MLP 學習門牌號碼資料集\n",
    "\n",
    "訓練一個 MLP 模型來學習門牌號碼資料集。\n",
    "\n",
    "注意：MLP 模型的能力有限，可能會導致訓練起來效果不佳。\n",
    "\n",
    "注意：近期 Flux 正在持續更新，請確保您的 Julia 在 v1.3 版以上，以及 Flux 在 v0.10.4 以上或是最新版。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458].\n",
      "└ @ Base loading.jl:1033\n",
      "┌ Info: Precompiling DataDeps [124859b0-ceae-595e-8997-d05f6a7a8dfe]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing DataDeps [124859b0-ceae-595e-8997-d05f6a7a8dfe].\n",
      "└ @ Base loading.jl:1033\n",
      "┌ Info: Precompiling HTTP [cd3eb016-35fb-5094-929b-558a96fad6f3]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Warning: Module MbedTLS with build ID 4906264239951 is missing from the cache.\n",
      "│ This may mean MbedTLS [739be429-bea8-5141-9913-cc70e7f3736d] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing HTTP [cd3eb016-35fb-5094-929b-558a96fad6f3].\n",
      "└ @ Base loading.jl:1033\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
    "using MLDatasets\n",
    "using Statistics\n",
    "import CuArrays\n",
    "CuArrays.allowscalar(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "呼叫 SVHN2 資料集的過程中，會先去檢查以前是否有下載過，如果是第一次下載，過程中會詢問是否下載資料集，請回答 `y`。整個資料集的大小約為 1.6 GB，下載時間可能會稍久，請耐心等候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency SVHN2.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: The Street View House Numbers (SVHN) Dataset\n",
      "Authors: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\n",
      "Website: http://ufldl.stanford.edu/housenumbers\n",
      "Format: Cropped Digits (Format 2 on the website)\n",
      "Note: for non-commercial use only\n",
      "\n",
      "[Netzer et al., 2011]\n",
      "    Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\n",
      "    \"Reading Digits in Natural Images with Unsupervised Feature Learning\"\n",
      "    NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011\n",
      "\n",
      "The dataset is split up into three subsets: 73257\n",
      "digits for training, 26032 digits for testing, and\n",
      "531131 additional to use as extra training data.\n",
      "\n",
      "The files are available for download at the official\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. For example the website mentions that\n",
      "the data is for non-commercial use only. Please read\n",
      "the website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\", \"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\", \"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\"] to \"/home/ghost/.julia/datadeps/SVHN2\"?\n",
      "[y/n]\n",
      "stdin> y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Float32[0.14901961 0.15294118 … 0.19607843 0.1882353; 0.15294118 0.15294118 … 0.2 0.1882353; … ; 0.16470589 0.16862746 … 0.1764706 0.17254902; 0.15294118 0.15294118 … 0.16470589 0.16470589]\n",
       "\n",
       "Float32[0.40392157 0.40784314 … 0.45882353 0.4509804; 0.40784314 0.40784314 … 0.4627451 0.4509804; … ; 0.40392157 0.39607844 … 0.45490196 0.4509804; 0.38039216 0.38039216 … 0.44313726 0.44313726]\n",
       "\n",
       "Float32[0.23529412 0.23921569 … 0.29803923 0.2901961; 0.23921569 0.23921569 … 0.3019608 0.2901961; … ; 0.24313726 0.24705882 … 0.28235295 0.2784314; 0.22352941 0.22352941 … 0.27058825 0.2784314]\n",
       "\n",
       "Float32[0.5058824 0.5254902 … 0.5411765 0.5137255; 0.49803922 0.52156866 … 0.50980395 0.47843137; … ; 0.48235294 0.49411765 … 0.39607844 0.43529412; 0.48235294 0.49019608 … 0.4392157 0.48235294]\n",
       "\n",
       "Float32[0.5568628 0.5882353 … 0.59607846 0.5686275; 0.56078434 0.58431375 … 0.5647059 0.53333336; … ; 0.5254902 0.5372549 … 0.41960785 0.4627451; 0.5294118 0.5372549 … 0.4627451 0.50980395]\n",
       "\n",
       "Float32[0.6 0.627451 … 0.64705884 0.61960787; 0.59607846 0.61960787 … 0.6156863 0.58431375; … ; 0.6117647 0.6156863 … 0.5254902 0.5647059; 0.6156863 0.61960787 … 0.5647059 0.6117647]\n",
       "\n",
       "Float32[0.5882353 0.5882353 … 0.5764706 0.62352943; 0.5882353 0.5921569 … 0.5764706 0.62352943; … ; 0.5882353 0.6 … 0.54509807 0.59607846; 0.5764706 0.5882353 … 0.5411765 0.59607846]\n",
       "\n",
       "Float32[0.627451 0.627451 … 0.64705884 0.69411767; 0.6392157 0.6392157 … 0.6431373 0.69411767; … ; 0.67058825 0.67058825 … 0.60784316 0.65882355; 0.6627451 0.6627451 … 0.60784316 0.65882355]\n",
       "\n",
       "Float32[0.6627451 0.6627451 … 0.7019608 0.7411765; 0.6666667 0.6627451 … 0.7019608 0.74509805; … ; 0.70980394 0.7058824 … 0.6666667 0.7137255; 0.7058824 0.7019608 … 0.67058825 0.7176471]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.4509804 0.47843137 … 0.45882353 0.5176471; 0.45490196 0.48235294 … 0.45882353 0.52156866; … ; 0.44705883 0.4627451 … 0.56078434 0.56078434; 0.4509804 0.46666667 … 0.5647059 0.5647059]\n",
       "\n",
       "Float32[0.5176471 0.54509807 … 0.47843137 0.5411765; 0.52156866 0.54901963 … 0.47843137 0.54901963; … ; 0.53333336 0.54509807 … 0.6117647 0.6117647; 0.53333336 0.54509807 … 0.6156863 0.6156863]\n",
       "\n",
       "Float32[0.5568628 0.5803922 … 0.5372549 0.59607846; 0.56078434 0.58431375 … 0.5372549 0.59607846; … ; 0.5568628 0.5686275 … 0.6431373 0.64705884; 0.56078434 0.57254905 … 0.64705884 0.64705884]\n",
       "\n",
       "Float32[0.3764706 0.3764706 … 0.38431373 0.38039216; 0.38039216 0.38039216 … 0.3882353 0.3882353; … ; 0.34117648 0.34117648 … 0.4627451 0.43529412; 0.34509805 0.34509805 … 0.43137255 0.40784314]\n",
       "\n",
       "Float32[0.25490198 0.25490198 … 0.2627451 0.25882354; 0.25490198 0.25490198 … 0.27450982 0.27058825; … ; 0.24313726 0.24705882 … 0.3882353 0.36078432; 0.24705882 0.2509804 … 0.35686275 0.33333334]\n",
       "\n",
       "Float32[0.18431373 0.1882353 … 0.18039216 0.1764706; 0.19215687 0.19607843 … 0.1882353 0.1882353; … ; 0.21568628 0.21176471 … 0.3254902 0.2901961; 0.21960784 0.21568628 … 0.29411766 0.26666668]\n",
       "\n",
       "Float32[0.39607844 0.42745098 … 0.40784314 0.37254903; 0.39215687 0.41960785 … 0.4117647 0.3764706; … ; 0.37254903 0.3647059 … 0.4 0.4; 0.3764706 0.3647059 … 0.4 0.4]\n",
       "\n",
       "Float32[0.29411766 0.32941177 … 0.3254902 0.28627452; 0.28627452 0.3137255 … 0.32941177 0.2901961; … ; 0.24705882 0.23921569 … 0.2784314 0.2784314; 0.2509804 0.23921569 … 0.2784314 0.2784314]\n",
       "\n",
       "Float32[0.23529412 0.27058825 … 0.2784314 0.24313726; 0.23529412 0.2627451 … 0.28627452 0.24705882; … ; 0.20392157 0.19607843 … 0.19607843 0.19607843; 0.2 0.19215687 … 0.19607843 0.19607843], [5, 2, 1, 10, 6, 1, 9, 1, 1, 8  …  1, 7, 1, 3, 6, 2, 2, 7, 6, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = SVHN2.traindata(Float32)\n",
    "test_X,  test_y  = SVHN2.testdata(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×26032 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  0  1  0  0  1  0  1  1  0  0  0  0  …  1  0  1  0  1  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  1  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0     0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  1     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  1  0  …  0  0  0  0  0  0  1  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  1  0  1\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = Flux.flatten(train_X)\n",
    "test_X = Flux.flatten(test_X)\n",
    "train_y = onehotbatch(train_y, 1:10)\n",
    "test_y = onehotbatch(test_y, 1:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "(10, 73257)\n"
     ]
    }
   ],
   "source": [
    "println(size(train_X)[1])\n",
    "println(size(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader((Float32[0.14901961 0.5058824 … 0.3764706 0.39607844; 0.15294118 0.49803922 … 0.38039216 0.39215687; … ; 0.2784314 0.5647059 … 0.2901961 0.19607843; 0.2784314 0.6117647 … 0.26666668 0.19607843], Bool[0 0 … 0 0; 0 1 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 1024, 26032, true, 26032, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  26023, 26024, 26025, 26026, 26027, 26028, 26029, 26030, 26031, 26032], false)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 1024\n",
    "train = DataLoader(train_X, train_y, batchsize=batchsize, shuffle=true)\n",
    "test = DataLoader(test_X, test_y, batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(3072, 512, relu), Dense(512, 256, relu), Dense(256, 128, relu), Dense(128, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "  Dense(size(train_X)[1], 512, relu),\n",
    "  Dense(512, 256, relu),\n",
    "  Dense(256, 128, relu),\n",
    "  Dense(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(3072, 512, relu), Dense(512, 256, relu), Dense(256, 128, relu), Dense(128, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = gpu.(train)\n",
    "test = gpu.(test)\n",
    "model = gpu(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_loss()\n",
    "    l = 0f0\n",
    "    for (x, y) in test\n",
    "        l += loss(x, y)\n",
    "    end\n",
    "    l/length(test)\n",
    "end\n",
    "evalcb() = @show(test_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 42.70032f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.7373888f0\n",
      "test_loss() = 3.1995196f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.413848f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.259804f0\n",
      "test_loss() = 4.746982f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2130752f0\n",
      "test_loss() = 2.1868994f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.24002f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.22434f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 11\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.20437f0\n",
      "test_loss() = 2.2037942f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 12\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 13\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2238953f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 14\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.1987612f0\n",
      "test_loss() = 2.2000926f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 15\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 16\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.224125f0\n",
      "test_loss() = 2.1629694f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 17\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n",
      "┌ Info: Epoch 18\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2180212f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 19\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.1869698f0\n",
      "test_loss() = 2.2180097f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 20\n",
      "└ @ Main /home/ghost/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2239914f0\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "@epochs epochs Flux.train!(loss, params(model), train, ADAM(0.005), cb=throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function accuracy(data_loader, model)\n",
    "    acc = 0\n",
    "    for (x,y) in data_loader\n",
    "        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))*1 / size(x,2)\n",
    "    end\n",
    "    acc/length(data_loader)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21953947141224633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22431445868945868"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
